{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b32a4a23-103f-4728-9568-c6b7465a8bc5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Marrying Grounding DINO with Stable Diffusion for Image Editing\n",
    "\n",
    "\n",
    "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/IDEA-Research/GroundingDINO)\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2303.05499-b31b1b.svg)](https://arxiv.org/abs/2303.05499) \n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wxWDt5UiwY8)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb)\n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/cMa77r3YrDk)\n",
    "[![HuggingFace space](https://img.shields.io/badge/ðŸ¤—-HuggingFace%20Space-cyan.svg)](https://huggingface.co/spaces/ShilongLiu/Grounding_DINO_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49a55a8f-d80f-4057-8048-09850be68e6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![gdsd](https://huggingface.co/ShilongLiu/GroundingDINO/resolve/main/gdsd_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef55e4a3-dccc-4c26-9a7a-899e0ba0e2f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Install diffusers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e997827a-a29e-4265-9986-1cbbdc14cbf3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "! pip install diffusers transformers accelerate scipy safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bcfe855-f10d-4641-b8cb-65c5cfb04d2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54087cd1-5a15-4a99-ad94-b96056f0fdae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "import groundingdino.datasets.transforms as T\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ebf8f32-7abf-419d-a54c-542e4676d915",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load grounding dino models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9ef5be8-8161-4718-aab4-2af3eb79928e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file) \n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "    _ = model.eval()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc694001-b7a7-4d13-9178-27f3069fa2b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swint_ogc.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinT_OGC.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cecd68e7-6ad3-4b62-8474-65e03c977dc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd774a81-70a9-45af-8a1e-98519dd5cdce",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load stable diffusion inpainting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54b717bd-e9c1-4879-864e-4f5590a7cc49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32d8b1df-9188-41cd-a58f-745aa2230d5a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load demo image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1c3fa58-27eb-4394-b175-f440edcfe8e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_url = 'https://huggingface.co/ShilongLiu/GroundingDINO/resolve/main/cats.png'\n",
    "local_image_path = 'cats.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "254e3bfa-71c0-42e1-be83-e76b47a3128e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "def download_image(url, image_file_path):\n",
    "    r = requests.get(url, timeout=4.0)\n",
    "    if r.status_code != requests.codes.ok:\n",
    "        assert False, 'Status code error: {}.'.format(r.status_code)\n",
    "\n",
    "    with Image.open(io.BytesIO(r.content)) as im:\n",
    "        im.save(image_file_path)\n",
    "\n",
    "    print('Image downloaded from url: {} and saved to: {}.'.format(url, image_file_path))\n",
    "\n",
    "download_image(image_url, local_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b53cb3d-0c88-477e-96f4-4dc56aff563d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run Grounding DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5177d8a-4ba6-414f-9043-5fb114e8afdd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "\n",
    "\n",
    "TEXT_PROMPT = \"the black cat .\"\n",
    "BOX_TRESHOLD = 0.45\n",
    "TEXT_TRESHOLD = 0.25\n",
    "\n",
    "image_source, image = load_image(local_image_path)\n",
    "\n",
    "boxes, logits, phrases = predict(\n",
    "    model=model, \n",
    "    image=image, \n",
    "    caption=TEXT_PROMPT, \n",
    "    box_threshold=BOX_TRESHOLD, \n",
    "    text_threshold=TEXT_TRESHOLD\n",
    ")\n",
    "\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "\n",
    "# image_source: np.ndarray\n",
    "# annotated_frame: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87c6c716-2422-4292-b1ae-e9ee878d3714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_masks_with_grounding(image_source, boxes):\n",
    "    h, w, _ = image_source.shape\n",
    "    boxes_unnorm = boxes * torch.Tensor([w, h, w, h])\n",
    "    boxes_xyxy = box_convert(boxes=boxes_unnorm, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
    "    mask = np.zeros_like(image_source)\n",
    "    for box in boxes_xyxy:\n",
    "        x0, y0, x1, y1 = box\n",
    "        mask[int(y0):int(y1), int(x0):int(x1), :] = 255\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3bec546c-db40-4d10-8074-34c37ff7a5ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_mask = generate_masks_with_grounding(image_source, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91cb3ced-9948-43f3-b590-270e67ba2af6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(image_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d50a34f4-07dd-4c54-b9e9-65c17d5805c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60821223-8ebf-41e7-886c-4f4412635d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ae3a8d9-7441-4096-80c2-1a62690d7263",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# image_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b18ff4ed-fe3f-4359-9027-a53b7e5908a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Image Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8bc71b5-1a27-4af2-9f8c-a25af8e790f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_source = Image.fromarray(image_source)\n",
    "annotated_frame = Image.fromarray(annotated_frame)\n",
    "image_mask = Image.fromarray(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cf754f5-6434-48be-88d7-82531a071fba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_source_for_inpaint = image_source.resize((512, 512))\n",
    "image_mask_for_inpaint = image_mask.resize((512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f23cb29f-6b54-4391-8785-b6d2f8d81c86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"a cute dinosaur\"\n",
    "#image and mask_image should be PIL images.\n",
    "#The mask structure is white for inpainting and black for keeping as is\n",
    "image_inpainting = pipe(prompt=prompt, image=image_source_for_inpaint, mask_image=image_mask_for_inpaint).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d96dd7e1-5682-4d24-a46f-d9b55097adbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_inpainting = image_inpainting.resize((image_source.size[0], image_source.size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0b7e347-ebc7-443e-b1e1-aa75c9e240df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f53cc860-132e-46c6-807a-980be180f33f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "image_editing_with_groundingdino_stablediffusion",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
