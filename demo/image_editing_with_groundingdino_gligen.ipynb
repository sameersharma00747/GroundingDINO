{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d2f14bf-9b7a-476e-87d7-decc4aea0854",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Marrying Grounding DINO with GLIGEN for Image Editing\n",
    "\n",
    "\n",
    "[![Grounding DINO](https://badges.aleen42.com/src/github.svg)](https://github.com/IDEA-Research/GroundingDINO)\n",
    "[![GLIGEN](https://badges.aleen42.com/src/github.svg)](https://github.com/gligen/GLIGEN)\n",
    "\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2303.05499-b31b1b.svg)](https://arxiv.org/abs/2303.05499) \n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wxWDt5UiwY8)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/zero-shot-object-detection-with-grounding-dino.ipynb)\n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/cMa77r3YrDk)\n",
    "[![HuggingFace space](https://img.shields.io/badge/ðŸ¤—-HuggingFace%20Space-cyan.svg)](https://huggingface.co/spaces/ShilongLiu/Grounding_DINO_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d039fd5-c40e-4e85-8b2e-49bedb49e987",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![gdgligen](https://huggingface.co/ShilongLiu/GroundingDINO/resolve/main/GD_GLIGEN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "049044a6-7a50-45cb-b287-3e5ed291d1ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Build environment\n",
    "\n",
    "**GLIGEN uses a modified diffusers. We highly recommoned to use new conda virtural environment for the notebook!**\n",
    "\n",
    "To do this, please run the following commands and rerun the notebook with the new environment:\n",
    "\n",
    "```bash\n",
    "conda create -n gligen_diffusers python=3.10\n",
    "conda activate gligen_diffusers\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "863aed73-d2a4-4032-9a51-268d767870d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "! pip install diffusers transformers accelerate scipy safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251a9121-e68c-4e82-9346-0c7801694bcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# install gligen_diffusers\n",
    "! pwd\n",
    "! git clone git@github.com:gligen/diffusers.git\n",
    "! python -m pip install -e diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11bcc0fc-f2f9-4603-86cd-6d77dbb84fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# setup device. If you have a GPU, you can change this to \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "149d1b84-83b6-43f0-85f8-201663b4f818",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from functools import partial\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "import groundingdino.datasets.transforms as T\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b5671fa-05eb-468b-b80c-679f2b2b3cd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load grounding dino models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22b2ec21-8d65-4e1c-97c3-76efe8e936f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
    "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
    "\n",
    "    args = SLConfig.fromfile(cache_config_file) \n",
    "    model = build_model(args)\n",
    "    args.device = device\n",
    "\n",
    "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
    "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
    "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
    "    _ = model.eval()\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb11073b-6914-426e-a011-84e7fe4ea6ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swint_ogc.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinT_OGC.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e2a98fd-895f-4f9a-8d52-f2b741524002",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abb87898-2fae-4293-a529-13331cc82d16",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load GLIGEN inpainting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0f41c53-6970-42cb-88fc-f0a60469fbe6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionGLIGENPipeline\n",
    "\n",
    "\n",
    "pipe = StableDiffusionGLIGENPipeline.from_pretrained(\"gligen/diffusers-inpainting-text-box\", revision=\"fp16\", torch_dtype=torch.float16)\n",
    "pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5fbf0f2-c611-4130-a68e-ba814863accc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Load demo image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3302f9a5-c64c-4711-bc59-9bd401b0c618",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_url = 'https://huggingface.co/ShilongLiu/GroundingDINO/resolve/main/art_dog_birthdaycake.png'\n",
    "local_image_path = 'art_dog_birthdaycake.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff8eb021-0a2b-47da-bbd6-67a6ceeac140",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "\n",
    "def download_image(url, image_file_path):\n",
    "    r = requests.get(url, timeout=4.0)\n",
    "    if r.status_code != requests.codes.ok:\n",
    "        assert False, 'Status code error: {}.'.format(r.status_code)\n",
    "\n",
    "    with Image.open(io.BytesIO(r.content)) as im:\n",
    "        im.save(image_file_path)\n",
    "\n",
    "    print('Image downloaded from url: {} and saved to: {}.'.format(url, image_file_path))\n",
    "\n",
    "download_image(image_url, local_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e6e612f-3a41-460e-a2cd-859fed6c5cba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Run Grounding DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5f4ebbd-ad61-4efe-bfb5-1bf6c2f27892",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "\n",
    "\n",
    "TEXT_PROMPT = \"dog. cake.\"\n",
    "BOX_TRESHOLD = 0.35\n",
    "TEXT_TRESHOLD = 0.25\n",
    "\n",
    "image_source, image = load_image(local_image_path)\n",
    "\n",
    "boxes, logits, phrases = predict(\n",
    "    model=model, \n",
    "    image=image, \n",
    "    caption=TEXT_PROMPT, \n",
    "    box_threshold=BOX_TRESHOLD, \n",
    "    text_threshold=TEXT_TRESHOLD\n",
    ")\n",
    "\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "\n",
    "# image_source: np.ndarray\n",
    "# annotated_frame: np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8f5f823-ac51-49a1-bc8b-01ee00e78761",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_masks_with_grounding(image_source, boxes):\n",
    "    h, w, _ = image_source.shape\n",
    "    boxes_unnorm = boxes * torch.Tensor([w, h, w, h])\n",
    "    boxes_xyxy = box_convert(boxes=boxes_unnorm, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
    "    mask = np.zeros_like(image_source)\n",
    "    for box in boxes_xyxy:\n",
    "        x0, y0, x1, y1 = box\n",
    "        mask[int(y0):int(y1), int(x0):int(x1), :] = 255\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88939d81-158c-4a32-af93-8025dcd771d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_mask = generate_masks_with_grounding(image_source, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8664984-799c-41e8-8839-ca2e5cb91917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(image_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad3807f0-7489-411a-9388-c736b77bf707",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(annotated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72e671f0-95fb-4778-bdc3-c719adf41e50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(image_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38b37eb5-cb97-4163-9dda-285ed0a43378",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Image Inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9d99cef-01f7-413c-83c6-abedf90ea6e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_source = Image.fromarray(image_source)\n",
    "annotated_frame = Image.fromarray(annotated_frame)\n",
    "image_mask = Image.fromarray(image_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84301435-fb99-4c1d-8ca8-47c2afb38e25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_source_for_inpaint = image_source.resize((512, 512))\n",
    "image_mask_for_inpaint = image_mask.resize((512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4205323-5ff3-4b2f-8382-bef4b7adbda2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "num_box = len(boxes)\n",
    "num_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e52b9a4c-d621-4f75-87f1-88ec5d009b53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xyxy_boxes = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").tolist()\n",
    "xyxy_boxes[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "766cb456-da21-45dd-9b3b-95f97e20c1e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define prompts for each box\n",
    "gligen_phrases = ['a cat', 'a rose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df458aa3-09c7-4bdd-abd0-4433acd592c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"'a cat', 'a rose'\"\n",
    "\n",
    "num_box = len(boxes)\n",
    "\n",
    "image_inpainting = pipe(\n",
    "    prompt,\n",
    "    num_images_per_prompt = 2,\n",
    "    gligen_phrases = gligen_phrases,\n",
    "    gligen_inpaint_image = image_source_for_inpaint,\n",
    "    gligen_boxes = xyxy_boxes,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"numpy\",\n",
    "    num_inference_steps=50\n",
    ").images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b290c9bc-8d6b-4c75-b2ae-56a1a5050629",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 0..1 to 0..255, and convert to uint8\n",
    "image_inpainting = (image_inpainting * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41fcb61e-e6cf-46c2-a322-ea7d7e20315e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "image_inpainting = np.concatenate(image_inpainting, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ed9d02e-3e87-4cbe-ac71-489a7671678b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Image.fromarray(image_inpainting).resize((image_source.size[0]*2, image_source.size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99aa36e9-afcd-4a5b-8527-9ce575ce4ba1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "image_editing_with_groundingdino_gligen",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
